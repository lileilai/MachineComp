{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import LightGBM as lgb\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_param(train_data,col,i):\n",
    "    y = train_data[col[i]]\n",
    "    x = train_data.drop(col,axis = 1)\n",
    "\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=2018)\n",
    "#     print (\"训练数据集样本数目：%d, 测试数据集样本数目：%d\" % (x_train.shape[0], x_test.shape[0]))\n",
    "    \n",
    "    min_error = float('Inf')\n",
    "    params = {}  #记录参数\n",
    "    best_params = {} #记录最优的参数\n",
    "    \n",
    "    \n",
    "    clf = lgb.LGBMRegressor(\n",
    "            objective ='regression',\n",
    "            learning_rate = 0.1,\n",
    "            subsample = 0.8,\n",
    "            colsample_bytree = 0.8,\n",
    "            reg_alpha = 1,\n",
    "            reg_lambda = 1,\n",
    "            max_depth = 10,\n",
    "            min_child_weight = 1,    \n",
    "        )\n",
    "    \n",
    "    # 调参1 提高准确率\n",
    "    print('调参1 提高准确率')\n",
    "    \n",
    "    for num_leaves in range(20,200,5):\n",
    "        for max_depth in range(3,8,1):\n",
    "            \n",
    "            params['num_leaves'] = num_leaves\n",
    "            params['max_depth'] = max_depth\n",
    "            \n",
    "            clf.set_params(**params)\n",
    "            \n",
    "            score = cross_val_score(clf,x,y,scoring='neg_mean_squared_log_error',cv=5)\n",
    "            score = np.array(score*-1)\n",
    "            print(score)\n",
    "            if score.min() < min_error:\n",
    "                min_error = score.min()\n",
    "                best_params['num_leaves'] = num_leaves\n",
    "                best_params['max_depth'] = max_depth\n",
    "                \n",
    "    if best_params.__contains__('num_leaves') and best_params.__contains__('max_depth'):\n",
    "        print('best num_leaves:',best_params['num_leaves'])\n",
    "        print('best max_depth: ',best_params['max_depth'])\n",
    "        print('error:' ,min_error)\n",
    "        \n",
    "        clf.set_params(**best_params)\n",
    "        \n",
    "    \n",
    "    #调参2 降低拟合\n",
    "    \n",
    "    print('调参2 降低过拟合')\n",
    "    \n",
    "    for max_bin in range(1,255,5):\n",
    "        for min_data_in_leaf in range(10,200,5):\n",
    "            params['max_bin'] = max_bin\n",
    "            params['min_data_in_leaf'] = min_data_in_leaf\n",
    "            \n",
    "            clf.set_params(**params)\n",
    "            \n",
    "            score = cross_val_score(clf,x,y,scoring='neg_mean_squared_log_error',cv=5)\n",
    "            score = np.array(-1*score)\n",
    "            if score.min() < min_error:\n",
    "                min_error = score.min()\n",
    "                best_params['max_bin'] = max_bin\n",
    "                best_params['min_data_in_leaf'] = min_data_in_leaf\n",
    "    \n",
    "    if best_params.__contains__('max_bin') and best_params.__contain__('min_data_in_leaf'):\n",
    "        print('best max_bin: ',best_params['max_bin'])\n",
    "        print('best min_data_in_leaf:', best_params['min_data_in_leaf'])\n",
    "        print('error: ',min_error)\n",
    "        clf.set_params(**best_params)\n",
    "    \n",
    "#     # 调参3 降低过拟合\n",
    "#     print('调参3 降低过拟合')\n",
    "#     for feature_fraction in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "#         for bagging_fraction in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "#             for bagging_freq in range(0,50,5):\n",
    "#                 params['feature_fraction'] = feature_fraction\n",
    "#                 params['bagging_fraction'] = bagging_fraction\n",
    "#                 params['bagging_freq'] = bagging_freq\n",
    "                \n",
    "#                 clf.set_params(**params)\n",
    "                \n",
    "#                 clf.fit(x_train,y_train)\n",
    "                \n",
    "#                 y_pre = clf.predict(x_test)\n",
    "                \n",
    "#                 score = cross_val_score(clf,x,y,scoring='neg_mean_squared_log_error',cv=5)\n",
    "                \n",
    "#                 if score < min_error:\n",
    "#                     min_error = score\n",
    "#                     best_params['feature_fraction'] = feature_fraction\n",
    "#                     best_params['bagging_fraction'] = bagging_fraction\n",
    "#                     best_params['bagging_freq'] = bagging_freq\n",
    "                    \n",
    "#     if best_params.__contain__('feature_fraction'):\n",
    "        \n",
    "#         print('best feature_fraction:',best_params['feature_fraction'])\n",
    "#         print('best bagging_fraction:',best_params['bagging_fraction'])\n",
    "#         print('best bagging_freq:', best_params['bagging_freq'])\n",
    "#         print('error:',min_error)\n",
    "        \n",
    "#         clf.set_params(**best_params)\n",
    "        \n",
    "    \n",
    "    # 调参4 降低过拟合\n",
    "    \n",
    "    print(\"调参4：降低过拟合\")\n",
    "    for reg_alpha in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        for reg_lambda in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "            for min_split_gain in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "                params['reg_alpha'] = reg_alpha\n",
    "                params['reg_lambda'] = reg_lambda\n",
    "                params['min_split_gain'] = min_split_gain\n",
    "                \n",
    "                clf.set_params(**params)\n",
    "                \n",
    "                score = cross_val_score(clf,x,y,scoring='neg_mean_squared_log_error',cv=5)\n",
    "                score = np.array(-1*score)\n",
    "                if score.min() < min_error:\n",
    "                    min_error = score.min()\n",
    "                    best_params['reg_alpha'] = reg_alpha\n",
    "                    best_params['reg_lambda'] = reg_lambda\n",
    "                    best_params['min_split_gain'] = min_split_gain\n",
    "                   \n",
    "    if best_params.__contains___('reg_alpha'):\n",
    "        print('best reg_alpha: ',best_params['reg_alpha'])\n",
    "        print('best reg_lambda:',best_params['reg_lambda'])\n",
    "        print('error:',min_error)\n",
    "        \n",
    "        clf.set_params(**params)\n",
    "        \n",
    "    print('finished!')\n",
    "    \n",
    "    return clf\n",
    "                \n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetIndex(df):\n",
    "    vid = df['vid']\n",
    "    df = df.drop('vid',axis=1)\n",
    "    df = df.set_index(vid)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_data,test_data,col,num):\n",
    "    \n",
    "    train_data = resetIndex(train_data)\n",
    "    \n",
    "    test_data = resetIndex(test_data)\n",
    "    \n",
    "    x = train_data\n",
    "    y = train_data[col]\n",
    "    x = x.drop(col,axis=1)\n",
    "    res = pd.DataFrame(index=test_data.index)\n",
    "    for i in range(len(col)):\n",
    "        clf = adjust_param(train_data,col,i)\n",
    "        clf.fit(x,y[col[i]])\n",
    "        y_pre = clf.predict(test_data)\n",
    "        \n",
    "        res[col[i]] = y_pre\n",
    "    \n",
    "    res.to_csv('./submit/'+str(num)+'.csv',encoding='gbk',header=None)\n",
    "    print('finished!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    col = ['收缩压','舒张压','血清甘油三酯','血清高密度脂蛋白','血清低密度脂蛋白']\n",
    "    path = './data/'\n",
    "    \n",
    "    p_train= path+'train_set_with_topic1.csv'\n",
    "    p_test = path+'test_set_with_topic1.csv'\n",
    "    \n",
    "    train_data = pd.read_csv(p_train,encoding='gbk')\n",
    "    test_data = pd.read_csv(p_test,encoding='gbk')\n",
    "    \n",
    "    run(train_data,test_data,col,20)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
